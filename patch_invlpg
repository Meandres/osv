diff --git a/arch/x64/mmu.cc b/arch/x64/mmu.cc
index 675410d0..6f49a4fb 100644
--- a/arch/x64/mmu.cc
+++ b/arch/x64/mmu.cc
@@ -47,6 +47,64 @@ namespace mmu {
 
 uint8_t phys_bits = max_phys_bits, virt_bits = 52;
 
+void invlpg_tlb_entry(void* addr){
+	asm volatile("invlpg (%0)" :: "r" (addr) : "memory");
+}
+
+mutex tlb_invlpg_mutex;
+sched::thread_handle tlb_invlpg_waiter;
+std::atomic<int> tlb_invlpg_pendingconfirms;
+std::vector<void*> pages_to_invalidate;
+
+void invlpg_tlb_entry_range(){
+	for(void* addr: pages_to_invalidate){
+	invlpg_tlb_entry(addr);
+    }
+}
+
+inter_processor_interrupt tlb_invlpg_ipi{IPI_TLB_INVLPG, []{
+	invlpg_tlb_entry_range();
+		if(tlb_invlpg_pendingconfirms.fetch_sub(1) == 1){
+			tlb_invlpg_waiter.wake_from_kernel_or_with_irq_disabled();
+		}
+	}
+};
+
+void invlpg_tlb_all(std::vector<void*> addresses){
+    pages_to_invalidate.clear();
+    for(void* addr: addresses){
+	    pages_to_invalidate.push_back(addr);
+    }
+    std::vector<sched::cpu*> ipis(sched::max_cpus);
+
+    if (sched::cpus.size() <= 1) {
+		invlpg_tlb_entry_range();
+		return;
+    }
+
+    SCOPE_LOCK(migration_lock);
+    invlpg_tlb_entry_range();
+    std::lock_guard<mutex> guard(tlb_invlpg_mutex);
+    tlb_invlpg_waiter.reset(*sched::thread::current());
+    int count;
+    ipis.clear();
+    for(sched::cpu* c: sched::cpus){
+	    if(c!=sched::cpu::current()){
+		    ipis.push_back(c);
+	    }
+    }
+    count = ipis.size();
+
+    tlb_invlpg_pendingconfirms.store(count);
+    tlb_invlpg_ipi.send_allbutself();
+
+    sched::thread::wait_until([] {
+            return tlb_invlpg_pendingconfirms.load() == 0;
+    });
+    tlb_invlpg_waiter.clear();
+
+}
+
 void flush_tlb_local() {
     // TODO: we can use page_table_root instead of read_cr3(), can be faster
     // when shadow page tables are used.
diff --git a/include/osv/interrupt.hh b/include/osv/interrupt.hh
index 22170cfb..a9803027 100644
--- a/include/osv/interrupt.hh
+++ b/include/osv/interrupt.hh
@@ -51,6 +51,7 @@ protected:
 enum ipi_id {
     IPI_WAKEUP,
     IPI_TLB_FLUSH,
+    IPI_TLB_INVLPG,
     IPI_SAMPLER_START,
     IPI_SAMPLER_STOP,
     IPI_SMP_STOP,
diff --git a/include/osv/mmu-defs.hh b/include/osv/mmu-defs.hh
index 0fc69afc..eaf63cd2 100644
--- a/include/osv/mmu-defs.hh
+++ b/include/osv/mmu-defs.hh
@@ -96,6 +96,13 @@ enum {
     pte_cow = 0,
 };
 
+// Invalidate TLB entry (locally)
+void invlpg_tlb_entry(void* addr);
+// Invalidate TLB entry range (locally)
+void invlpg_tlb_entry_range();
+// Invalidate TLB range locally and sends IPI to all other CPUs
+void invlpg_tlb_all(std::vector<void*> addresses);
+
 /* flush tlb for the current processor */
 void flush_tlb_local();
 /* flush tlb for all */
